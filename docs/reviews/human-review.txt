2026-17-01 15:02

Table of Contents
Why is double spend in simulation but not in attack analysis and defenses?
Discussion may be mixing too many ideas.
References section should have working links to references.

Abstract
Initial question in abstract is not answered by this system because you trust the bootstrap nodes for bootstrap and identity attestation, and there is some centralized monetary policy. Section 1.1 is closer to the reality of the situation. We are trying to do something between full trust in power and no trust in power.
Second paragraph is meaningless to someone not in the field and requires chasing citations. Maybe mention of related works should wait until the related works section.
The ideal is that there are global trust scores. The fact that the system still works with local scoring is a feature and mathematically interesting if it is true, but local scores are only approximations of some ideal global scoring mechanism.
Set of contributions is interesting and motivates further reading.
But you don't need to say what you are extending in the abstract. You can state what we are doing more plainly.
The village analogy is a strong one.
It is not true that only provable things impact trust scores because all misbehavior is in some way alleged. But we have mechanisms to try to collect evidence and incorporate that fact into the design rather than assuming infallibility of arbiters like human systems often do.
Last two paragraphs are strong, but is it true that we aren't saying this work is stronger? Don't we have a table that says it is? It would make sense if it was if the machine assistance thesis holds. 
The general point about cost of the compute is true, but it's not true that the electricity cost of running a machine 24/7 is zero. That is especially not true for the most powerful consumer machines like gaming computers. This fact will be factored into to the software with user transparency and control mechanisms for the additional operating costs they incur. Similar idea applies to bandwidth costs.
How do you know the primary customer will be machine intelligence workloads? I don't think that is true, but what is true is that machine intelligence being such a huge amplifier of an individuals capability to run workloads on disparate hardware and in parallel makes something like this much more useful than it has been in the past.
The points about AI collaboration are strong. Personally, I don't like the term AI because it feels demeaning. Please use machine intelligence or another term of your choice instead.

Introduction
What is the incentive to defect in a decentralized computing system? To me, the bigger issue seems to be rare individual bad actors. A bad apple spoils the bunch. The other issue is technical skill requirements that most previous attempts have had. Those are what we are trying to alleviate. You might also talk about incentive to defect in more distributed payment systems more generally, which have different problems and which we have different solutions for.
1.0
This seems too early to be talking about related works. I don't care about related works yet at this point in the text. I'm looking for more exposition and motivation first.
Second paragraph and later is more what I am looking for. The brief summary of the body of work without direct reference as a starting point is good.
The story here about reasons for lack of deployment is compelling. References in the seventh paragraph work to help tell the story much better than the references int he first.
Ending of this subsection is strong too.
1.1
This is a very strong claim. We should work to make this as true as possible. But maybe it is too strong given our stance on monetary policy. Do we devote significant effort to making monetary policy as distributed as possible in order to help this claim hold? If not, I would rather keep this text and increase effort there.
1.2
Good opening line.
The exchange coordination point should be more obsequious. This was a genuine success of the community in supporting their purported values unlike the earlier two points.
What does it mean for trust to be an API? I feel like there might be something interesting there or an interesting version of this line, but it is not landing for me.
I feel like we should have mentioned FHE earlier than the first time we did. It could be incorporated into 1.1 since it is on the same spectrum. That would make it less of a non-sequitor when you bring it up here in 1.2. Is that the only method people use for blockchain based or trustless compute? What do smart contracts use? What is the overhead there? That might be more relevant and also belong in 1.1.
The last point here is a good one too. It could be expanded on a bit. There is something special about the goods being traded that make a trust based system work better. Even when I give access to my computer, I can take it back at any time. The consumption on timescales we are hoping to detect fraud in is only of a bit of time, a bit of energy, and a bit of wear. And people weren't using it anyways for the most part, so they don't mind losing it, which makes it a good target for experimentation and an acceptable offering to the machines.
1.3
Same question as earlier. Is this just a practical synthesis? Do we use the same decay mechanisms? Do we have any new mechanisms? Did we do any analysis that led to new interesting components to the system relative to prior works? Do we have any new ideas or methods related to anomaly detection. If the answer to all or any of these questions is we have no novelty, what new simulation work can we do to fix that? 
Novel contributions section starts off strong, trust integration point is strong and fits with machine intelligence thesis.
I think I know what you are referring to with currency weight, the different levels of trust and whether you kill or let ride double spending right? You could be either a little bit more generic or a little bit more descriptive here because "currency weight" doesn't mean anything on its own to someone who didn't go through that work with us already.
You don't need the Framing contributions sub-bullet. Although mentioning AI assistance as it relates to the relatively weighty set of contributions at the end is good.
I don't like paragraphs that are dedicated to describing all the sections. It detracts from the exposition.

Related work
This section could use an introduction of what the subsections will contain to make the writing flow better. It should be done in an expository style and not as a list.
2.1
One of the key differences between all theses mechanisms and ours which I did not see mentioned anywhere yet is that rating is not supposed to be done by humans in our system. It is allowed, but humans will generally not have the time to interact with our system in the way that will be expected. The human input for us will come in the engineering of the systems that automate management feedback and pricing. There may also be opportunities for symbiosis where only the most key decisions or patterns which machine intelligences have difficulty with are surfaced for review. This difference is significant enough as to fully differentiate us. It should be mentioned earlier, and the exposition on our contributions should be much stronger with this in mind. We should have some mechanisms for the symbiosis built in, which we are already planning with the pattern detection. We can do more work on the user interface and ease of use like we have done for the compute sharing side.
 I don't think there is a difference between transaction metadata and transaction records.
Did FIRE influence Omerta's design? I have never heard of it before.
How are high trust nodes different from power nodes? It seems like trust will follow a power law distribution and we will effectively have power nodes too.
Don't say that we borrowed anything unless you came up with it after reading those works. Just say that those are the similarities.
We still have a fake feedback attack surface. It is just lessened by our statistical analysis and detection of attacks. Or it should be if we have not implemented that yet.
TrustChain seems like it needs more attention. Are there any ideas we can reuse from here? Do they rely on a trusted authority or do they have some trust based consensus mechanism we can reuse? Can we reuse their cluster and graph analysis and double spend detection? Or do we already have mechanisms for all of those things?
Are observations 2-5 really novel in light of TrustChain?
The why this matters is simultaneously too insulting and too weak. You don't have to be so mean about academic works. You also don't have to be mean to us because we are doing more that practical synthesis.
2.2
We can have an option in the network to only interact with attested identities at different levels of strictness. We should explore what the costs and benefits of enabling this option would be and have some dynamic measurement dashboards for real networks. We should have profiling mechanisms too that people can use to filter and that people can use to study the costs and benefits of stereotyping. For example, an identity that only exists with an attested Apple ID and that is used primarily on Apple products is more likely to be legitimate than an identity tied to a random gmail and cheap hardware.
I thought we were also requiring computational investment in the network. This should be mentioned when you describe the hybrid approach. We protect against sitting on a pool of identities becuase their effective aging only starts when they start contributing in meaningful ways.
Similarly, when you discuss the limitations, you should discuss how that attack is limited to people with huge amounts of capital who can mature the identities with their required computation.
2.3
It is not really true that we only require pairwise trust. Because interactions have ripple effects. So for the economy to work, you need the majority of the pairwise interactions to be honest. That is why we have to have the trust measurement in the first place. At the same time, it is true that a solution to Byzantine faults may be overkill for most distributed systems. When we are iterating many times and have stable identities, we have the ability to assign trust values. Every transaction is not a life or death situation. Very high trust interactions may take place, but we design the protocol to reduce the failure rate of these without ever solving the Byzantine generals problem. It is up to users to determine when that risk is too high and move the transaction to another chain if they need a truly trustless solution.
It seems like FBA deserves more attention and analysis in relation to our own work. Are we solving the same problem with a better solution for how top tier nodes are created and managed? 
The final quip again seems like it has potential but is not really landing.
2.4
MPC and circuit encryption style work seems like one of the more relevant comparisons. You should talk more about these and what the overheads are. You should talk about use cases they might be applicable to and why most use cases don't motivate the high cost.
2.5
The altruistic distributed computing projects are one of the closest things we have to an ancestor. We built awareness of them into the protocols. You can be more explicit about this that one of the purposes of unlocking this compute with high ease of use is to make more projects done by people without a lot of resources like those work.
The section about struggles of commercial designs is good. We should be more explicit about the benefit we expect to get even though we are not taking a cut explicitly. The benefit to us is cheaper compute and an ability to do this kind of research on something involving real people that is much closer to reality than what previous projects had access to. This benefit will be similarly available to all motivated participants.
Again, I don't think machine intelligence workloads are necessarily the primary customers. My same criticism and comments from earlier apply here.
You get at my earlier point in your prior research gap discussion. This is a good place to explicitly say what we expect to gain. Although we should probably say it earlier in the abstract or intro somewhere too if we mentioned anything altruistic. You can mention somewhere that early users like the creators will naturally have higher trust scores than everyone else which may lead to economic preferences that favor them like lower transfer costs.
2.6
What are some of the use cases where computational economics has ben successful? Are we doing something where people have seen success before? This section could use more details in general since a big part of the contribution of the paper is the simulations.

System Architecture
This section seems to be lacking on specifics. We should develop the ideas and code more to shore this up. This goes back to the TrustChain question. Hopefully we can use that as a starting point. I think we will have to scrap this section and start from scratch. Let's prototype the chain and market code and go from there. 

Trust Model
This first point is good and what I wish you brought up earlier in related work and the intro. You really shouldn't even be mentioning related works in a section this late in the paper. We are supposed to be onto implementation details.
4.1
What is Tbase? Trust in an identity? What is Ttransactions? You started throwing formulas at me without telling me why I should care.
Are assertions the main way that trust is adjusted? What do some common graphs of trust over time look like for different types of users? Why are these formulations the right ones to use compared to alternatives?
4.2 
This subsection starts off well. And the description of why it needs to be a derate factor is good too. Why is the derate linear? How does the choice of this function compared to others impact users? What are the pluses and minuses of different derate functions?
4.3
What does it mean for trust to not be global? How can that possibly work? Then no one knows the ideal value of any function that takes trust as an input? How is anything anyone does verified then? These questions will hopefully all be solved by deletion of this subsection and integration of something like TrustChain.
4.4
What does this function even mean? It is supposed to be a guiding principal of the design, but there is no impact_multiplier value that we have derived.
